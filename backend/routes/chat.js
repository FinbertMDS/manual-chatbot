const express = require("express");
const router = express.Router();
const { getEmbeddingsBatch } = require("../services/embedding");
const { searchSimilar } = require("../services/vectordb");
// const { createAnswerFromContext } = require("../services/answer"); // optional n·∫øu mu·ªën t√≥m t·∫Øt tr·∫£ l·ªùi

const { CohereClient } = require("cohere-ai");

const cohere = new CohereClient({
  token: process.env.COHERE_API_KEY,
});

// POST /api/chat
router.post("/", async (req, res) => {
  try {
    const { question } = req.body;

    // üëâ 1. T·∫°o embedding t·ª´ question (Cohere)
    const [queryEmbedding] = await getEmbeddingsBatch([question]);
    
    // üëâ 2. T√¨m c√°c ƒëo·∫°n vƒÉn g·∫ßn nh·∫•t t·ª´ vectordb
    const searchResults = await searchSimilar(queryEmbedding, 5); // l·∫•y top 3 context g·∫ßn nh·∫•t
    
    const topMatches = searchResults.documents[0].map((text, i) => ({
      text,
      id: searchResults.ids[0][i],
      score: searchResults.distances[0][i],
    }));
    
    // üëâ 3. Tr·∫£ l·∫°i k·∫øt qu·∫£ (ho·∫∑c b·∫°n c√≥ th·ªÉ gh√©p l·∫°i th√†nh 1 c√¢u tr·∫£ l·ªùi)
    const context = topMatches.map((doc) => doc.text).join('\n---\n');

    // 3. Ask Cohere to generate an answer
    const response = await cohere.generate({
      model: 'command-r-plus',
      prompt: `B·∫°n l√† tr·ª£ l√Ω AI. D·ª±a tr√™n th√¥ng tin d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.\n\nTh√¥ng tin:\n${context}\n\nC√¢u h·ªèi: ${question}\n\nTr·∫£ l·ªùi:`,
      maxTokens: 300,
      temperature: 0.3,
    });

    const answer = response.generations?.[0]?.text || "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi.";

    // 4. Return full result
    res.json({
      answer,
      results: topMatches,
      context,
    });
  } catch (error) {
    console.error("‚ùå Chat error:", error.message);
    res.status(500).json({ error: "Chat failed" });
  }
});

module.exports = router;
